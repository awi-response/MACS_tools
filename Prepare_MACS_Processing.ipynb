{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to move raw MACS files based on extracted footprints files \n",
    "**author:** Ingmar Nitze, Tabea Rettelbach, Simon SchÃ¤ffler\n",
    "\n",
    "**contact:** ingmar.nitze@awi.de\n",
    "\n",
    "**version date:** 2022-03-03\n",
    "\n",
    "**repository and other tools** https://github.com/awi-response/MACS_tools\n",
    "\n",
    "**CONDA Environment** please use *MACS37* conda environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "1. Setup folder structure\n",
    "2. convert MACS files to TIFF with *mipps* including devignetting\n",
    "3. Rescale image values **Optional**\n",
    "4. Crop corners of images **Optional**\n",
    "5. Prepare nav files for Pix4d\n",
    "6. PostProcessing to CIR mosiac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* prefer full/absolute paths\n",
    "* Create processing template automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Set project directory here, where you want to process your data\n",
    "PROJECT_DIR =  = Path(r'')\n",
    "#PROJECT_DIR = Path(r'D:\\Pix4D_Processing\\tests\\autofootprints_DPT_logging')\n",
    "#PROJECT_DIR = r'D:\\pix4d_Processing\\ThawTrendAir_2019\\Image_Test_CODEscaleHi' # SET Project output\n",
    "\n",
    "# Name of Pix4dProject\n",
    "#PIX4d_PROJECT_NAME = 'Meade_merged'\n",
    "PIX4d_PROJECT_NAME = Path(PROJECT_DIR).name\n",
    "#PIX4d_PROJECT_NAME = 'Meade_merged' # Add name here for custom named pix4dProject\n",
    "\n",
    "# SET AOI for footprints selection\n",
    "AOI = Path(r'')\n",
    "#AOI = Path(r'S:\\p_macsprocessing\\test_sites\\site_definitions\\test_ARF.shp')\n",
    "#AOI = Path(r'S:\\p_macsprocessing\\test_sites\\site_definitions\\test_DPT.shp')\n",
    "#AOI = Path(r'S:\\p_macsprocessing\\test_sites\\site_definitions\\test_TUK.shp')\n",
    "\n",
    "# determine which sensors to include in processing (possible options: 'left', 'right', 'nir')\n",
    "sensors = ['left', 'right', 'nir']\n",
    "\n",
    "# SET SCALING \n",
    "SCALING = 1\n",
    "SCALE_LOW = False # Set to True to use calculated lower boundary - skews NDVI\n",
    "SCALE_HIGH = True # Set to True to use calculated upper boundary\n",
    "SCALING_EMPIRICAL = False\n",
    "\n",
    "\n",
    "# Set CROP CORNER if \n",
    "CROP_CORNER = 0 # SET to 1 if you want to crop corners (set to NoData)\n",
    "DISK_SIZE = 5200 # Cropping diameter, the larger the fewer no data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "import sys\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from joblib import delayed, Parallel, wrap_non_picklable_objects\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from processing_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = Path(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed Settings\n",
    "* These Settings can be kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018 Canada\n",
    "PARENT_DIRS = [Path(r'N:\\response\\Restricted_Airborne\\MACs\\Canada\\1_MACS_original_images'),\n",
    "              Path(r'N:\\response\\Restricted_Airborne\\MACs\\Alaska\\ThawTrend-Air_2019\\raw_data'),\n",
    "              Path(r'N:\\response\\Restricted_Airborne\\MACs\\2021_Perma-X_Alaska\\01_raw_data')\n",
    "              ]\n",
    "              \n",
    "# imageing projects footprint file\n",
    "PROJECTS_FILES = [Path(r'N:\\response\\Restricted_Airborne\\MACs\\Canada\\0_MACS_important_files\\1_all_canada_flights_2018_footprints\\all_canada_flights_2018_footprints_datasets.shp'),\n",
    "                  Path(r'N:\\response\\Restricted_Airborne\\MACs\\Alaska\\ThawTrend-Air_2019\\footprints\\ThawTrendAir2019_MACS_footprints_datasets.shp'),\n",
    "                  Path(r'N:\\response\\Restricted_Airborne\\MACs\\2021_Perma-X_Alaska\\03_footprints\\Perma-X\\PermaX2021_MACS_footprints_datasets.shp')\n",
    "                 ]\n",
    "\n",
    "CODE_DIR = pwd\n",
    "MIPPS_DIR = r'C:\\Program Files\\DLR MACS-Box\\bin'\n",
    "MIPPS_BIN = r'..\\tools\\MACS\\mipps.exe'\n",
    "EXIF_PATH = Path(CODE_DIR / Path(r'exiftool\\exiftool.exe'))\n",
    "mipps_script_dir = Path('mipps_scripts')\n",
    "\n",
    "mipps_script_nir = '33552_all_taps_2018-09-26_12-58-15_modelbased.mipps'\n",
    "mipps_script_right = '33576_all_taps_2018-09-26_13-13-43_modelbased.mipps'\n",
    "mipps_script_left = '33577_all_taps_2018-09-26_13-21-24_modelbased.mipps'\n",
    "\n",
    "mipps_script_nir = pwd / mipps_script_dir / mipps_script_nir\n",
    "mipps_script_right = pwd / mipps_script_dir / mipps_script_right\n",
    "mipps_script_left = pwd / mipps_script_dir / mipps_script_left\n",
    "\n",
    "DATA_DIR = Path(PROJECT_DIR) / '01_rawdata' / 'tif'\n",
    "OUTDIR = {'right': DATA_DIR / Path('33576_Right'),\n",
    "          'left':DATA_DIR / Path('33577_Left'),\n",
    "          'nir':DATA_DIR / Path('33552_NIR')}\n",
    "tag = {'right':'MACS_RGB_Right_33576',\n",
    "       'left':'MACS_RGB_Left_33577',\n",
    "       'nir':'MACS_NIR_33552'}\n",
    "\n",
    "# Path of filtered footprints file (.shp file)\n",
    "path_footprints = Path(PROJECT_DIR) / '02_studysites' / 'footprints.shp'\n",
    "outdir = os.path.join(PROJECT_DIR, '01_rawdata','tif')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare processing dir \n",
    "* check if exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zippath = os.path.join(CODE_DIR, 'processing_folder_structure_template.zip')\n",
    "nav_script_path = os.path.join(CODE_DIR, 'pix4dnav.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(zippath, 'r') as zip_ref:\n",
    "    zip_ref.extractall(PROJECT_DIR)\n",
    "shutil.copy(nav_script_path, outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger\n",
    "logging.basicConfig(filename=PROJECT_DIR / f'{PROJECT_DIR.name}.log', level=logging.INFO, format='%(asctime)s %(message)s', )\n",
    "logging.info('Creation of logfile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto Selection of footprints\n",
    "provide more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('Creating footprints selection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for projects_file, parent_dir in zip(PROJECTS_FILES, PARENT_DIRS):\n",
    "    dss = []\n",
    "    print(parent_dir.parent)\n",
    "    ds = get_overlapping_ds(AOI, projects_file, parent_dir)\n",
    "    #dss.append(ds)\n",
    "    if len(ds) > 0:\n",
    "        break\n",
    "stats = get_dataset_stats(ds, parent_dir, AOI)\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Dataset ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = input('Please select ID: ')\n",
    "footprints = retrieve_footprints(ds, dataset_id, parent_dir, AOI)\n",
    "print(\"Total number of images:\", len(footprints))\n",
    "print(\"NIR images:\", (footprints['Looking'] == 'center').sum())\n",
    "print(\"RGB right images:\", (footprints['Looking'] == 'right').sum())\n",
    "print(\"RGB left images:\", (footprints['Looking'] == 'left').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footprints.to_file(path_footprints)\n",
    "logging.info(f'Footprints file save to {path_footprints}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load filtered footprints file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = get_dataset_name(ds, dataset_id)\n",
    "path_infiles = Path(parent_dir) / dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = prepare_df_for_mipps(path_footprints, path_infiles)\n",
    "df_final['full_path'] = df_final.apply(lambda x: f'\"{x.full_path}\"', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of images:\", len(df_final))\n",
    "print(\"NIR images:\", (df_final['Looking'] == 'center').sum())\n",
    "print(\"RGB right images:\", (df_final['Looking'] == 'right').sum())\n",
    "print(\"RGB left images:\", (df_final['Looking'] == 'left').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(MIPPS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_roll = 3 # Select maximum roll angle to avoid image issues - SET in main settings part?\n",
    "chunksize = 20 # this is a mipps-script thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export MACS to TIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f'Start exporting MACS files to TIFF using DLR mipps')\n",
    "logging.info(f\"Total number of images: {len(df_final)}\")\n",
    "logging.info(f\"NIR images: {(df_final['Looking'] == 'center').sum()}\")\n",
    "logging.info(f\"RGB right images: {(df_final['Looking'] == 'right').sum()}\")\n",
    "logging.info(f\"RGB left images:{(df_final['Looking'] == 'left').sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is relevant for NIR only\n",
    "if 'nir' in sensors:\n",
    "    logging.info(f'Start transforming NIR files')\n",
    "    logging.info(f'MIPPS Script: {mipps_script_nir.name}')\n",
    "    \n",
    "    looking = 'center'\n",
    "    q = (np.abs(df_final['Roll[deg]']) < max_roll) & (df_final['Looking'] == looking)\n",
    "    df_nir = df_final[q]\n",
    "    print(len(df_nir))\n",
    "    split = len(df_nir) // chunksize\n",
    "    if split == 0: split+=1\n",
    "    for df in tqdm.tqdm_notebook(np.array_split(df_nir, split)):\n",
    "        outlist = ' '.join(df['full_path'].values[:])\n",
    "        s = f'{MIPPS_BIN} -c={mipps_script_nir} -o={outdir} -j=4 {outlist}'\n",
    "        os.system(s)\n",
    "        #print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is RGB\n",
    "if 'right' in sensors:\n",
    "    logging.info(f'Start transforming RGB right files')\n",
    "    logging.info(f'MIPPS Script: {mipps_script_right.name}')\n",
    "    \n",
    "    looking = 'right'\n",
    "    q = (np.abs(df_final['Roll[deg]']) < max_roll) & (df_final['Looking'] == looking)\n",
    "    df_right = df_final[q]\n",
    "    split = len(df_right) // chunksize\n",
    "    if split == 0: split+=1\n",
    "    for df in tqdm.tqdm_notebook(np.array_split(df_right, split)):\n",
    "        outlist = ' '.join(df['full_path'].values[:])\n",
    "        s = f'{MIPPS_BIN} -c={mipps_script_right} -o={outdir} -j=4 {outlist}'\n",
    "        os.system(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'left' in sensors:\n",
    "    logging.info(f'Start transforming RGB left files')\n",
    "    logging.info(f'MIPPS Script: {mipps_script_left.name}')\n",
    "    \n",
    "    looking = 'left'\n",
    "    q = (np.abs(df_final['Roll[deg]']) < max_roll) & (df_final['Looking'] == looking)\n",
    "    df_left = df_final[q]\n",
    "    split = len(df_left) // chunksize\n",
    "    if split == 0: split+=1\n",
    "    for df in tqdm.tqdm_notebook(np.array_split(df_left, split)):\n",
    "        outlist = ' '.join(df['full_path'].values[:])\n",
    "        s = f'{MIPPS_BIN} -c={mipps_script_left} -o={outdir} -j=4 {outlist}'\n",
    "        os.system(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescale image values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SCALING:\n",
    "    logging.info(f'Start reading Image statistics')\n",
    "    %time df_stats = get_image_stats_multi(OUTDIR, sensors, nth_images=1, quiet=False, n_jobs=40)\n",
    "    #absolute\n",
    "    if SCALE_LOW:\n",
    "        scale_lower = int(df_stats['min'].mean().round())\n",
    "    else:\n",
    "        scale_lower = 1\n",
    "    if SCALE_HIGH:\n",
    "        scale_upper = int(df_stats['max'].mean().round())\n",
    "    else:\n",
    "        scale_upper = 2*16-1\n",
    "    print(f'Mean of minimums: {scale_lower}')\n",
    "    print(f'Mean of maximums: {scale_upper}')\n",
    "    logging.info(f'Mean of minimums: {scale_lower}')\n",
    "    logging.info(f'Mean of maximums: {scale_upper}')\n",
    "    logging.info(f'Finished reading Image statistics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SCALING_EMPIRICAL:\n",
    "    # empirical\n",
    "    df_stats2 = df_stats.replace({'left':'RGB', 'right':'RGB'})\n",
    "    grouped = df_stats2.groupby('sensor').mean()\n",
    "    empirical_scale_factor = (grouped.loc['nir'] / grouped.loc['RGB'] / 0.8)['min']\n",
    "else: \n",
    "    empirical_scale_factor = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run scaling\n",
    "* minimum default to 1\n",
    "* consistency for final index calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SCALING:\n",
    "    logging.info(f'Start Image Scaling')\n",
    "    n_jobs = 20\n",
    "    for sensor in sensors:\n",
    "        print(f'Processing {sensor}')\n",
    "        #shutter_factor\n",
    "        images = list(OUTDIR[sensor].glob('*.tif'))[:]\n",
    "        if sensor in ['right', 'left']:\n",
    "            shutter_factor = get_shutter_factor(OUTDIR, sensors) * empirical_scale_factor\n",
    "            print(f'RGB to NIR factor = {shutter_factor}')\n",
    "        else:\n",
    "            shutter_factor = 1\n",
    "        \n",
    "        %time _ = Parallel(n_jobs=n_jobs)(delayed(write_new_values)(image, scale_lower, scale_upper, shutter_factor=shutter_factor, tag=True) for image in tqdm.tqdm_notebook(images[:]))\n",
    "    logging.info(f'Finished Image Scaling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crop Corners of images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CROP_CORNER:\n",
    "    logging.info(f'Start Cropping corners')\n",
    "    logging.info(f'Disk Size: {DISK_SIZE}')\n",
    "    for sensor in sensors[:]:\n",
    "        mask = make_mask((3232, 4864), disksize=DISK_SIZE)\n",
    "        images = list(OUTDIR[sensor].glob('*'))\n",
    "        if sensor != 'nir':\n",
    "            mask = np.r_[[mask]*3]\n",
    "        %time _ = Parallel(n_jobs=4)(delayed(mask_and_tag)(image, mask, tag=None) for image in tqdm.tqdm_notebook(images))\n",
    "    logging.info(f'Finished Cropping corners')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write exif information into all images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f'Start writing EXIF Tags')\n",
    "for sensor in tqdm.tqdm_notebook(sensors):\n",
    "    print(sensor)\n",
    "    %time write_exif(OUTDIR[sensor], tag[sensor], EXIF_PATH)\n",
    "logging.info(f'Finished writing EXIF Tags')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f'Start preparing nav file')\n",
    "\n",
    "navfile = list(Path(path_infiles).glob('*nav.txt'))[0]\n",
    "shutil.copy(navfile, OUTDIR['nir'].parent / 'nav.txt')\n",
    "os.chdir(OUTDIR['nir'].parent)\n",
    "os.system('python pix4dnav.py')\n",
    "\n",
    "logging.info(f'Finished preparing nav file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Run Pix4d Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 4 band CIR mosaic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this part after Processing in Pix4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(Path(PROJECT_DIR) / '04_pix4d' / Path(PROJECT_DIR).name / '3_dsm_ortho' / '2_mosaic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbfile = list(Path('.').glob('*group1.tif'))[0]\n",
    "nirfile = list(Path('.').glob('*nir.tif'))[0]\n",
    "outmosaic = '_'.join(rgbfile.name.split('_')[:-3])+'_mosaic.tif'\n",
    "\n",
    "dsm_dir = dir_processed = Path(PROJECT_DIR) / '04_pix4d' / PIX4d_PROJECT_NAME / '3_dsm_ortho' / '1_dsm'\n",
    "dsm_file = list(dsm_dir.glob('*dsm.tif'))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export single bands and merge afterwards \n",
    "* make function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f'Start restructuring and mosaicking final Orthomosaics!')\n",
    "\n",
    "for band in [1,2,3]:\n",
    "    s = f'gdalbuildvrt -b {band} rgb_{band}.vrt {rgbfile}'\n",
    "    os.system(s)\n",
    "\n",
    "for band in [1]:\n",
    "    s = f'gdalbuildvrt -b {band} nir_{band}.vrt {nirfile}'\n",
    "    os.system(s)\n",
    "\n",
    "s = f'gdalbuildvrt -separate 4band.vrt rgb_3.vrt rgb_2.vrt rgb_1.vrt nir_1.vrt'\n",
    "os.system(s)\n",
    "\n",
    "s = f'gdal_translate -a_nodata 0 -co COMPRESS=DEFLATE -co BIGTIFF=YES 4band.vrt {outmosaic}'\n",
    "os.system(s)\n",
    "\n",
    "for file in ['rgb_3.vrt', 'rgb_2.vrt', 'rgb_1.vrt', 'nir_1.vrt', '4band.vrt']:\n",
    "    os.remove(file)\n",
    "logging.info(f'Finished restructuring and mosaicking final Orthomosaics!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f'Start writing band names!')\n",
    "\n",
    "with rasterio.open(outmosaic, 'r+') as src:\n",
    "    src.set_band_description(1, 'MACS Blue Band')\n",
    "    src.set_band_description(2, 'MACS Green Band')\n",
    "    src.set_band_description(3, 'MACS Red Band')\n",
    "    src.set_band_description(4, 'MACS NIR Band')\n",
    "\n",
    "    logging.info(f'Finished writing band names!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f'Start updating mask of Orthomosaics!')\n",
    "\n",
    "with rasterio.open(outmosaic, 'r+') as src:\n",
    "    src.profile['nodata'] = 0\n",
    "    data = src.read()\n",
    "    newmask = ~(data == 0).any(axis=0)\n",
    "    newmask_write = np.r_[src.count * [newmask]]\n",
    "    data_masked = data * newmask_write\n",
    "    src.write(data_masked)\n",
    "    \n",
    "logging.info(f'Finished updating mask of Orthomosiacs!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Pyramids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f'Start calculating pyramid layers for Orthoimage!!')\n",
    "addo = f'gdaladdo -ro --config COMPRESS_OVERVIEW DEFLATE --config GDAL_NUM_THREADS ALL_CPUS {outmosaic}'\n",
    "os.system(addo)\n",
    "logging.info(f'Finished calculating pyramid layers for Orthoimage!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f'Start calculating pyramid layers for DSM!')\n",
    "addo = f'gdaladdo -ro --config COMPRESS_OVERVIEW DEFLATE --config GDAL_NUM_THREADS ALL_CPUS {dsm_file}'\n",
    "os.system(addo)\n",
    "logging.info(f'Finished calculating pyramid layers for DSM!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
